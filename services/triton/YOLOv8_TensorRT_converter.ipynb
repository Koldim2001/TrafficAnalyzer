{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gXjoyUkl1Wc"
      },
      "source": [
        "# YOLOv8 Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD26qSXamCfk"
      },
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJBju7PZmHYc"
      },
      "source": [
        "## Download the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHTp3kVsmKNi"
      },
      "outputs": [],
      "source": [
        "# Download YOLOv8 model\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brSTmpEmLTj"
      },
      "source": [
        "# Tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUff5dejmNHu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0pZtlcCmQkE"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt_lean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAhaRj11mS1m"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt_dispatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zR8n35m5Kp6"
      },
      "outputs": [],
      "source": [
        "!pip install onnx onnxsim onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UxZjv9JmUaY"
      },
      "outputs": [],
      "source": [
        "import tensorrt\n",
        "print(tensorrt.__version__)\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install ultralytics==8.2.38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V62zTVoImXKU"
      },
      "outputs": [],
      "source": [
        "# Export YOLOv8 Model to Tensorrt\n",
        "!yolo export model=yolov8m.pt format=engine half=True device=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ZYA3k2mgz8"
      },
      "source": [
        "## Inference on Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DhS9BTRml_z"
      },
      "outputs": [],
      "source": [
        "# Inference Using YOLOv8 Model\n",
        "!yolo detect predict model=yolov8m.pt source=\"https://ultralytics.com/images/bus.jpg\" device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QIl5j75mvyB"
      },
      "outputs": [],
      "source": [
        "# Inference Using YOLOv8 Tensorrt\n",
        "!yolo detect predict model=yolov8m.engine source=\"https://ultralytics.com/images/bus.jpg\" device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "img = cv2.imread(\"bus.jpg\")\n",
        "\n",
        "#model_path = \"yolov8m.pt\"\n",
        "model_path = \"yolov8m.engine\"\n",
        "\n",
        "model = YOLO(model_path, task='detect')\n",
        "classes = model.names\n",
        "    \n",
        "outputs = model.predict(img, imgsz=640, conf=0.5, verbose=True, iou=0.7)\n",
        "\n",
        "detected_conf = outputs[0].boxes.conf.cpu().tolist()\n",
        "detected_cls = outputs[0].boxes.cls.cpu().int().tolist()\n",
        "detected_cls = [classes[i] for i in detected_cls]\n",
        "detected_xyxy = outputs[0].boxes.xyxy.cpu().int().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx==1.15.0\n",
            "  Downloading onnx-1.15.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnx==1.15.0) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnx==1.15.0) (4.25.3)\n",
            "Downloading onnx-1.15.0-cp311-cp311-win_amd64.whl (14.3 MB)\n",
            "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/14.3 MB 1.3 MB/s eta 0:00:11\n",
            "   - -------------------------------------- 0.5/14.3 MB 4.7 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 1.2/14.3 MB 8.7 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 2.1/14.3 MB 10.9 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 2.2/14.3 MB 9.2 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.1/14.3 MB 10.9 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.1/14.3 MB 10.6 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 3.8/14.3 MB 10.1 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 4.2/14.3 MB 10.7 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 4.2/14.3 MB 10.7 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 4.9/14.3 MB 9.5 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 5.7/14.3 MB 10.1 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 6.4/14.3 MB 10.5 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 7.2/14.3 MB 11.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.2/14.3 MB 11.7 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 9.3/14.3 MB 12.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 10.3/14.3 MB 13.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 11.2/14.3 MB 14.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 12.2/14.3 MB 14.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.0/14.3 MB 15.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 13.4/14.3 MB 16.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 13.6/14.3 MB 16.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.3/14.3 MB 14.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.3/14.3 MB 14.2 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx\n",
            "  Attempting uninstall: onnx\n",
            "    Found existing installation: onnx 1.16.1\n",
            "    Uninstalling onnx-1.16.1:\n",
            "      Successfully uninstalled onnx-1.16.1\n",
            "Successfully installed onnx-1.15.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install onnx==1.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnxruntime==1.15.0\n",
            "  Downloading onnxruntime-1.15.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.15.0)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime==1.15.0)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: numpy>=1.24.2 in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnxruntime==1.15.0) (1.26.3)\n",
            "Requirement already satisfied: packaging in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnxruntime==1.15.0) (23.2)\n",
            "Requirement already satisfied: protobuf in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnxruntime==1.15.0) (4.25.3)\n",
            "Requirement already satisfied: sympy in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from onnxruntime==1.15.0) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.15.0)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\program files\\anaconda\\envs\\patched_yolo_infer\\lib\\site-packages (from sympy->onnxruntime==1.15.0) (1.3.0)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime==1.15.0)\n",
            "  Downloading pyreadline3-3.5.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading onnxruntime-1.15.0-cp311-cp311-win_amd64.whl (6.7 MB)\n",
            "   ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.7 MB 1.3 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 0.3/6.7 MB 3.4 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.8/6.7 MB 6.1 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 1.5/6.7 MB 8.9 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 2.1/6.7 MB 10.2 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.4/6.7 MB 9.0 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 3.1/6.7 MB 10.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 3.8/6.7 MB 10.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 4.6/6.7 MB 11.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 5.3/6.7 MB 11.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 6.1/6.7 MB 12.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.6/6.7 MB 12.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.7/6.7 MB 11.6 MB/s eta 0:00:00\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading pyreadline3-3.5.3-py3-none-any.whl (79 kB)\n",
            "   ---------------------------------------- 0.0/79.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 79.9/79.9 kB 4.4 MB/s eta 0:00:00\n",
            "Installing collected packages: flatbuffers, pyreadline3, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 onnxruntime-1.15.0 pyreadline3-3.5.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install onnxruntime==1.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n",
            "Ultralytics YOLOv8.2.39 üöÄ Python-3.11.8 torch-2.2.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti Laptop GPU, 16384MiB)\n",
            "YOLOv8m summary (fused): 218 layers, 25886080 parameters, 0 gradients, 78.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (49.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.8s, saved as 'yolov8m.onnx' (98.8 MB)\n",
            "\n",
            "Export complete (6.0s)\n",
            "Results saved to \u001b[1mC:\\–ú–ì–¢–£ –ù–ê–£–ö–ê\\–ü–†–û–ï–ö–¢–´ GIT –¥–ª—è –î–£–®–ò\\TrafficAnalyzer\\services\\triton\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8m.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8m.onnx imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/49.7M [00:00<?, ?B/s]\n",
            "  0%|          | 240k/49.7M [00:00<00:24, 2.14MB/s]\n",
            "  3%|‚ñé         | 1.41M/49.7M [00:00<00:06, 7.71MB/s]\n",
            "  7%|‚ñã         | 3.34M/49.7M [00:00<00:03, 13.1MB/s]\n",
            " 11%|‚ñà         | 5.44M/49.7M [00:00<00:02, 16.4MB/s]\n",
            " 15%|‚ñà‚ñå        | 7.47M/49.7M [00:00<00:02, 18.0MB/s]\n",
            " 20%|‚ñà‚ñà        | 10.0M/49.7M [00:00<00:02, 20.3MB/s]\n",
            " 25%|‚ñà‚ñà‚ñç       | 12.3M/49.7M [00:00<00:01, 20.9MB/s]\n",
            " 29%|‚ñà‚ñà‚ñâ       | 14.6M/49.7M [00:00<00:01, 21.5MB/s]\n",
            " 34%|‚ñà‚ñà‚ñà‚ñç      | 17.1M/49.7M [00:00<00:01, 22.8MB/s]\n",
            " 39%|‚ñà‚ñà‚ñà‚ñâ      | 19.3M/49.7M [00:01<00:01, 22.8MB/s]\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21.9M/49.7M [00:01<00:01, 24.1MB/s]\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 24.3M/49.7M [00:01<00:01, 24.2MB/s]\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 26.7M/49.7M [00:01<00:00, 24.7MB/s]\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 29.5M/49.7M [00:01<00:00, 25.8MB/s]\n",
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32.0M/49.7M [00:01<00:00, 25.5MB/s]\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 34.5M/49.7M [00:01<00:00, 25.4MB/s]\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37.1M/49.7M [00:01<00:00, 25.9MB/s]\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 39.6M/49.7M [00:01<00:00, 25.7MB/s]\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42.0M/49.7M [00:01<00:00, 25.1MB/s]\n",
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 44.5M/49.7M [00:02<00:00, 24.9MB/s]\n",
            " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 46.8M/49.7M [00:02<00:00, 24.5MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 49.5M/49.7M [00:02<00:00, 25.1MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [00:02<00:00, 22.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Export YOLOv8 Model to Tensorrt\n",
        "!yolo export model=yolov8m.pt format=onnx dynamic=True device=0 "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
